{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ea0eba",
   "metadata": {},
   "source": [
    "## Hyperparameters and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d7a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "whole_dataset = '/home/jadebustos/tfm/datasets/real-life-violence-situations/'\n",
    "\n",
    "video_path_train = '/home/jadebustos/tfm/datasets/video_tmp/full/train'\n",
    "video_path_validation = '/home/jadebustos/tfm/datasets/video_tmp/full/validation'\n",
    "video_path_test = '/home/jadebustos/tfm/datasets/video_tmp/full/test'\n",
    "\n",
    "imgs_path_train = '/home/jadebustos/tfm/datasets/imgs/lstm-16-frames/train'\n",
    "imgs_path_validation = '/home/jadebustos/tfm/datasets/imgs/lstm-16-frames/validation'\n",
    "\n",
    "# Hyperparams\n",
    "IMAGE_SIZE = 200\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
    "\n",
    "#input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
    "#input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "\n",
    "frames_per_video = 16\n",
    "\n",
    "labels = ['violence', 'nonviolence']\n",
    "labels_dict = {}\n",
    "labels_dict['violence'] = 0.\n",
    "labels_dict['nonviolence'] = 1.\n",
    "\n",
    "# get files in directory\n",
    "def get_files_dir(directory):\n",
    "    return os.listdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b09135",
   "metadata": {},
   "source": [
    "Split the original dataset in several datasets:\n",
    "\n",
    "* Train\n",
    "* Validation\n",
    "* Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea31a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "train_percent = 60\n",
    "validation_percent = 20\n",
    "test_percent = 20\n",
    "\n",
    "# remove old video directories and recreate them\n",
    "def create_dirs(path, labels):\n",
    "    !rm -Rf $path\n",
    "    for item in labels:\n",
    "        dir = os.path.join(path, item)\n",
    "        !mkdir -p $dir\n",
    "\n",
    "def copy_random_videos(src, dst, video_list, number):\n",
    "    # video index in video_list\n",
    "    index_videos = []\n",
    "    # generate random video index\n",
    "    while len(index_videos) != number:\n",
    "        rnd = random.randint(0, len(video_list)-1)\n",
    "        if rnd not in index_videos:\n",
    "            index_videos.append(rnd)\n",
    "\n",
    "    # copy videos\n",
    "    for i in index_videos:\n",
    "        src_video = os.path.join(src, video_list[i])\n",
    "        dst_video = os.path.join(dst, video_list[i])\n",
    "        shutil.copyfile(src_video, dst_video)\n",
    "\n",
    "    # remove select elements from video_list\n",
    "    for i in index_videos:\n",
    "        # replace copied videos index with -1\n",
    "        video_list[i] = -1\n",
    "    # remove all -1 indexes\n",
    "    video_list[:] = (value for value in video_list if value != -1)\n",
    "        \n",
    "create_dirs(video_path_train, labels)\n",
    "create_dirs(video_path_validation, labels)\n",
    "create_dirs(video_path_test, labels)\n",
    "\n",
    "violence_files = get_files_dir(os.path.join(whole_dataset, labels[0]))\n",
    "nonviolence_files = get_files_dir(os.path.join(whole_dataset, labels[1]))\n",
    "\n",
    "# violence\n",
    "validation_videos = int(len(violence_files) * (validation_percent/100))\n",
    "train_videos = int(len(violence_files) * (train_percent/100))\n",
    "test_videos = len(violence_files) - validation_videos - train_videos\n",
    "\n",
    "src = os.path.join(whole_dataset, labels[0])\n",
    "dst = os.path.join(video_path_validation, labels[0])\n",
    "copy_random_videos(src, dst, violence_files, validation_videos)\n",
    "\n",
    "dst = os.path.join(video_path_train, labels[0])\n",
    "copy_random_videos(src, dst, violence_files, train_videos)\n",
    "\n",
    "dst = os.path.join(video_path_test, labels[0])\n",
    "copy_random_videos(src, dst, violence_files, test_videos)\n",
    "\n",
    "# nonviolence\n",
    "validation_videos = int(len(nonviolence_files) * (validation_percent/100))\n",
    "train_videos = int(len(nonviolence_files) * (train_percent/100))\n",
    "test_videos = len(nonviolence_files) - validation_videos - train_videos\n",
    "\n",
    "src = os.path.join(whole_dataset, labels[1])\n",
    "dst = os.path.join(video_path_validation, labels[1])\n",
    "copy_random_videos(src, dst, nonviolence_files, validation_videos)\n",
    "\n",
    "dst = os.path.join(video_path_train, labels[1])\n",
    "copy_random_videos(src, dst, nonviolence_files, train_videos)\n",
    "\n",
    "dst = os.path.join(video_path_test, labels[1])\n",
    "copy_random_videos(src, dst, nonviolence_files, test_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c09573",
   "metadata": {},
   "source": [
    "Execute the following to get datasets size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e80441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training videos (violence): 600\n",
      "Training videos (nonviolence): 600\n",
      "\n",
      "Validation videos (violence): 200\n",
      "Validation videos (nonviolence): 200\n",
      "\n",
      "Test videos (violence): 200\n",
      "Test videos (nonviolence): 200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "\n",
    "files_dir = get_files_dir(os.path.join(video_path_train, 'violence'))\n",
    "print(\"Training videos (violence): %d\" % len(files_dir))\n",
    "files_dir = get_files_dir(os.path.join(video_path_train, 'nonviolence'))\n",
    "print(\"Training videos (nonviolence): %d\" % len(files_dir))\n",
    "\n",
    "files_dir = get_files_dir(os.path.join(video_path_validation, 'violence'))\n",
    "print(\"\\nValidation videos (violence): %d\" % len(files_dir))\n",
    "files_dir = get_files_dir(os.path.join(video_path_validation, 'nonviolence'))\n",
    "print(\"Validation videos (nonviolence): %d\" % len(files_dir))\n",
    "\n",
    "files_dir = get_files_dir(os.path.join(video_path_test, 'violence'))\n",
    "print(\"\\nTest videos (violence): %d\" % len(files_dir))\n",
    "files_dir = get_files_dir(os.path.join(video_path_test, 'nonviolence'))\n",
    "print(\"Test videos (nonviolence): %d\" % len(files_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f02ba4",
   "metadata": {},
   "source": [
    "Convert to frames. One image is picked every **N** frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f88b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting frames for training dataset (violence) ...\n",
      "Training images (violence): 600\n",
      "Getting frames for training dataset (nonviolence) ...\n",
      "Training images (nonviolence): 600\n",
      "Getting frames for validation dataset (violence) ...\n",
      "Validation images (violence): 200\n",
      "Getting frames for validation dataset (nonviolence) ...\n",
      "Validation images (nonviolence): 200\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# extract so many frames as BATCH_SIZE\n",
    "def video2frames(input_dir, output_dir, nframes):\n",
    "    videos = glob.glob(input_dir)\n",
    "\n",
    "    for item in videos:\n",
    "        # directory to store video frames\n",
    "        dir_name = os.path.join(output_dir, item.split('/')[-1].split('.')[0])\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "        frame_index = 1\n",
    "        vidcap = cv2.VideoCapture(item)\n",
    "        length = int(vidcap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "        # distance among video frames\n",
    "        step = (length // nframes)\n",
    "        # frames to capture\n",
    "        frames = []\n",
    "        for i in range(1, nframes):\n",
    "            frames.append(i * step)\n",
    "            \n",
    "        videoname, ext = os.path.basename(item).split('.')\n",
    "        \n",
    "        # read first frame\n",
    "        success, image = vidcap.read()\n",
    "        filename = videoname + '-' + format(0, '05d') + '.png'\n",
    "        resized = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        output_file = os.path.join(dir_name, filename)\n",
    "        cv2.imwrite(output_file, resized)\n",
    "        \n",
    "        for i in frames:\n",
    "            vidcap.set(1, i - 1)\n",
    "            success, image = vidcap.read()\n",
    "            filename = videoname + '-' + format(i, '05d') + '.png'\n",
    "            resized = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "            output_file = os.path.join(dir_name, filename)\n",
    "            cv2.imwrite(output_file, resized)\n",
    "            \n",
    "        # close video capture    \n",
    "        vidcap.release()\n",
    "    \n",
    "    return\n",
    "\n",
    "# delete frames directories\n",
    "!rm -Rf $imgs_path_train \n",
    "!rm -Rf $imgs_path_validation\n",
    "\n",
    "# create frames directories\n",
    "for item in labels:\n",
    "    directory = os.path.join(imgs_path_train, item)\n",
    "    !mkdir -p $directory\n",
    "    directory = os.path.join(imgs_path_validation, item)\n",
    "    !mkdir -p $directory\n",
    "    \n",
    "# muestreamos los videos de violencia (train)\n",
    "print(\"Getting frames for training dataset (violence) ...\")\n",
    "input_dir_train_violence = os.path.join(video_path_train, 'violence' + '/*')\n",
    "output_dir_train_violence = os.path.join(imgs_path_train, 'violence')\n",
    "video2frames(input_dir_train_violence, output_dir_train_violence, frames_per_video)\n",
    "files_dir = get_files_dir(os.path.join(imgs_path_train, 'violence'))\n",
    "print(\"Training images (violence): %d\" % len(files_dir))\n",
    "\n",
    "# muestreamos los videos de no violencia (train)\n",
    "print(\"Getting frames for training dataset (nonviolence) ...\")\n",
    "input_dir_train_nonviolence = os.path.join(video_path_train, 'nonviolence' + '/*')\n",
    "output_dir_train_nonviolence = os.path.join(imgs_path_train, 'nonviolence')\n",
    "video2frames(input_dir_train_nonviolence, output_dir_train_nonviolence, frames_per_video)\n",
    "files_dir = get_files_dir(os.path.join(imgs_path_train, 'nonviolence'))\n",
    "print(\"Training images (nonviolence): %d\" % len(files_dir))\n",
    "\n",
    "# muestreamos los videos de violencia (validation)\n",
    "print(\"Getting frames for validation dataset (violence) ...\")\n",
    "input_dir_validation_violence = os.path.join(video_path_validation, 'violence' + '/*')\n",
    "output_dir_validation_violence = os.path.join(imgs_path_validation, 'violence')\n",
    "video2frames(input_dir_validation_violence, output_dir_validation_violence, frames_per_video)\n",
    "files_dir = get_files_dir(os.path.join(imgs_path_validation, 'violence'))\n",
    "print(\"Validation images (violence): %d\" % len(files_dir))\n",
    "\n",
    "# muestreamos los videos de no violencia (validation)\n",
    "print(\"Getting frames for validation dataset (nonviolence) ...\")\n",
    "input_dir_validation_nonviolence = os.path.join(video_path_validation, 'nonviolence' + '/*')\n",
    "output_dir_validation_nonviolence = os.path.join(imgs_path_validation, 'nonviolence')\n",
    "video2frames(input_dir_validation_nonviolence, output_dir_validation_nonviolence, frames_per_video)\n",
    "files_dir = get_files_dir(os.path.join(imgs_path_validation, 'nonviolence'))\n",
    "print(\"Validation images (nonviolence): %d\" % len(files_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051daf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
